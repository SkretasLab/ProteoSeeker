import os
import sys


def help_par(text, step):
    words = text.split(" ")
    lines = [words[0]]
    for word in words[1:]:
        if len(lines[-1]) + len(word) < step:
            lines[-1] += (" " + word)
        else:
            lines.append(word)
    return lines


def help_message():
    print("comebin_metabinner_filter.py Version 1.0.0")
    print()
    print("Usage:")
    print("python comebin_metabinner_filter.py -i <annotation_file_path> -s <species_file_path> -o <output_file_path>")
    print()
    print("This tool can be used to filter the species identified by the COMEBin/MetaBinner route and filter a TXT annotation")
    print("file based on the filtered species. New files for the filtered species and the TXT annotation file are generated.")
    print()
    print("Option description:")
    print("1. Parameter type")
    print("2. Req: Required, Opt: Optional")
    print("3. Default value (shown if not empty or none)")
    print("4. Description")
    print()
    print("Options:")
    print("---------Input and output options---------")
    help_notes_dict = {
        "-i/--input": "Str -Req- The path to the TXT annotation file generated by ProteoSeeker..",
        "-s/--species": "Str -Req- The path to the species file generated by ProteoSeeker through the COMEBin/MetaBinner taxonomy route by COMEBin or MetaBinner.",
        "-o/--output": "Str -Req- The path to the species file generated by ProteoSeeker through the COMEBin/MetaBinner taxonomy route by COMEBin or MetaBinner."
    }
    split_step = 60
    for key_hn in help_notes_dict.keys():
        description = help_notes_dict[key_hn]
        des_length = len(description)
        if split_step >= des_length:
            print('{:2} {:30} {}\n'.format("", key_hn, description))
        else:
            pieces = help_par(description, split_step)
            for pmi in range(0, len(pieces)):
                piece_mod = pieces[pmi]
                if pmi == 0:
                    print('{:2} {:30} {}'.format("", key_hn, piece_mod))
                elif pmi + 1 == len(pieces):
                    print('{:33} {}\n'.format("", piece_mod))
                else:
                    print('{:33} {}'.format("", piece_mod))


def read_file(filename):
    file_handle = open(filename, "r")
    lines_raw = file_handle.readlines()
    lines = []
    for line in lines_raw:
        line = line.rstrip("\n")
        lines.append(line)
    file_handle.close()
    return lines


def ps_species_analyze(cm_species_path, output_dir_path):
    # bind      species_name                taxid   taxonomy_rank   lineage                                                                                                                                                                                     percentage_input_reads      percentage_preprocessed_reads
    # 0	        Cupriavidus	                106589	genus	        cellular organisms;Bacteria;Pseudomonadota;Betaproteobacteria;Burkholderiales;Burkholderiaceae;Cupriavidus                                                                                  1.48	                    1.48
    # 1	        Micromonospora krabiensis	307121	species	        cellular organisms;Bacteria;Terrabacteria group;Actinomycetota;Actinomycetes;Micromonosporales;Micromonosporaceae;Micromonospora;Micromonospora krabiensis                              	1.45	                    1.46
    # 1	        Nonomuraea sp. TT08I-71	    2733864	species	        cellular organisms;Bacteria;Terrabacteria group;Actinomycetota;Actinomycetes;Streptosporangiales;Streptosporangiaceae;Nonomuraea;unclassified Nonomuraea;Nonomuraea sp. TT08I-71	        1.45	                    1.46
    cmbn_sole_info_dict = {}
    species_lines = read_file(cm_species_path)
    # At first the bin IDs are filtered based on whether they correspond to one species or more.
    found_bin_ids = set()
    bin_ids_with_one_species = []
    bin_ids_with_mult_species = set()
    for line in species_lines:
        line_splited = line.split("\t")
        line_splited_length = len(line_splited)
        # The scientific name of the organism associated with a bin is automatically extracted by the protein headers of the protein database,
        # hence sometimes it may not contain an actual species name. Any line with not the expected number of information is skipped.
        if line_splited_length != 7:
            continue
        # Find the bin ID
        bin_id = line_splited[0]
        if bin_id not in found_bin_ids:
            found_bin_ids.add(bin_id)
        else:
            bin_ids_with_mult_species.add(bin_id)
    for fnid in found_bin_ids:
        if fnid not in bin_ids_with_mult_species:
            bin_ids_with_one_species.append(fnid)
    # Write the discarded bin IDs.
    multiple_bin_ids_path = "{}/bin_ids_multiple_species.txt".format(output_dir_path)
    multiple_bin_ids_file = open(multiple_bin_ids_path, "w")
    for mbid in bin_ids_with_mult_species:
        multiple_bin_ids_file.write("{}\n".format(mbid))
    multiple_bin_ids_file.close()
    # Collecting information for the bins asigned to one species.
    perc_sum = 0
    for line in species_lines:
        line_splited = line.split("\t")
        line_splited_length = len(line_splited)
        # The scientific name of the organism associated with a bin is automatically extracted by the protein headers of the protein database,
        # hence sometimes it may not contain an actual species name. Any line with not the expected number of information is skipped.
        if line_splited_length != 7:
            continue
        bin_id = line_splited[0]
        taxid = line_splited[2]
        # If the bin ID is one of the bin IDs for bins win one species then proceed.
        if bin_id in bin_ids_with_one_species:
            sole_percentage = line_splited[6]
            sole_percentage_fl = float(sole_percentage)
            if taxid not in cmbn_sole_info_dict.keys():
                cmbn_sole_info_dict[taxid] = [sole_percentage_fl, []]
                if bin_id not in cmbn_sole_info_dict[taxid][1]:
                    cmbn_sole_info_dict[taxid][1].append(bin_id)
                perc_sum += sole_percentage_fl
            else:
                cmbn_sole_info_dict[taxid][0] += sole_percentage_fl
                if bin_id not in cmbn_sole_info_dict[taxid][1]:
                    cmbn_sole_info_dict[taxid][1].append(bin_id)
                perc_sum += sole_percentage_fl
    perc_sum = round(perc_sum, 2)
    perc_sum_unclassified = 100 - perc_sum
    perc_sum_unclassified = round(perc_sum_unclassified, 2)
    # Write the information in a file.
    sp_sample_method_path = "{}/species_filtered.tsv".format(output_dir_path)
    sp_dir_file = open(sp_sample_method_path, "w")
    sp_dir_file.write("taxid\trelative abundance (%)\tmerged_bin_ids\n")
    for key_species in cmbn_sole_info_dict.keys():
        key_percentage = cmbn_sole_info_dict[key_species][0]
        bin_id_list = cmbn_sole_info_dict[key_species][1]
        sp_dir_file.write("{}\t{}".format(key_species, key_percentage))
        if bin_id_list:
            sp_dir_file.write("\t")
            for bin_id_index in range(0, len(bin_id_list)):
                bin_id_item = bin_id_list[bin_id_index]
                if (bin_id_index + 1) == len(bin_id_list):
                    sp_dir_file.write("{}".format(bin_id_item))
                else:
                    sp_dir_file.write("{},".format(bin_id_item))
        sp_dir_file.write("\n")
    sp_dir_file.write("unclassified\t{}\n".format(perc_sum_unclassified))
    sp_dir_file.close()
    return cmbn_sole_info_dict


def ps_annotation_analyze(annotation_txt_path, cmbn_sole_info_dict, output_dir_path):
    annotation_filtered_path = "{}/annotation_info_filtered.txt".format(output_dir_path)
    bin_id_found = False
    protein_taxonomy_found = False
    found_target_bin_id = False
    annotation_filtered_file = open(annotation_filtered_path, "w")
    with open(annotation_txt_path, "r") as annotation_lines:
        for line in annotation_lines:
            line = line.rstrip()
            # Bin ID information line.
            if bin_id_found:
                bin_id_str = line
                if bin_id_str != "-":
                    bin_id_int = int(bin_id_str)
                    # Determine whether the bin id exists in the filtered bin ids. If yes replace its bin ID with the bin IDs.
                    # If not replace its taxon/taxa with the note that its taxonomy could not be inferred.
                    found_target_bin_id = False
                    for key_species in cmbn_sole_info_dict.keys():
                        bin_id_list = cmbn_sole_info_dict[key_species][1]
                        for bin_id_target in bin_id_list:
                            bin_id_target_int = int(bin_id_target)
                            if bin_id_int == bin_id_target_int:
                                new_line = ",".join(bin_id_list)
                                found_target_bin_id = True
                                break
                    if not found_target_bin_id:
                        new_line = "-"
                else:
                    new_line = line
                bin_id_found = False
            elif protein_taxonomy_found:
                if found_target_bin_id:
                    new_line = line
                else:
                    new_line = "Could not be inferred."
                protein_taxonomy_found = False
            elif line == "Bin ID:":
                bin_id_found = True
                new_line = line
            elif "Protein taxonomy" in line:
                if found_target_bin_id:
                    new_line = line
                else:
                    new_line = "Protein taxonomy:"
                protein_taxonomy_found = True
            else:
                new_line = line
            annotation_filtered_file.write("{}\n".format(new_line))
    annotation_filtered_file.close()


def cmfilter(annotation_txt_path, cm_species_path, output_dir_path):
    if (not cm_species_path) or (cm_species_path == ""):
        print("Input annotation TXT file does not exist. Exiting.")
        exit()

    if output_dir_path or (output_dir_path != ""):
        if not os.path.exists(output_dir_path):
            os.mkdir(output_dir_path)

    # Collecting the information about the species predicted by COMEBin or MetaBinner and filtering them.
    print("Species file: {}".format(cm_species_path))
    cmbn_sole_info_dict = ps_species_analyze(cm_species_path, output_dir_path)

    # If an annotation file was provided then the annotation file is filtered based on the filtered species.
    if annotation_txt_path or (annotation_txt_path != ""):
        print("Processing input file: {}".format(annotation_txt_path))
        ps_annotation_analyze(annotation_txt_path, cmbn_sole_info_dict, output_dir_path)


if __name__ == "__main__":
    annotation_txt_path = ""
    cm_species_path = ""
    if len(sys.argv) > 1:
        arg_input_command = "{}".format(sys.argv[0])
        for i in range(1, len(sys.argv), 2):
            if sys.argv[i] == "-i" or sys.argv[i] == "--input":
                annotation_txt_path = sys.argv[i+1]
            elif sys.argv[i] == "-s" or sys.argv[i] == "--species":
                cm_species_path = sys.argv[i+1]
            elif sys.argv[i] == "-o" or sys.argv[i] == "--output":
                output_dir_path = sys.argv[i+1]
            elif sys.argv[i] == "-h" or sys.argv[i] == "--help":
                help_message()
                exit()
    cmfilter(annotation_txt_path, cm_species_path, output_dir_path)
